\title{Jobs}{jobs}

\use-plugin{concourse-docs}

\reference{jobs}{Jobs} determine the \italic{actions} of your pipeline. They
determine how \reference{resources}{resources} progress through it, and how the
pipeline is visualized.

The most important attribute of a job is its build plan, configured as
\reference{schema.job.plan}. This determines the sequence of \reference{steps} to
execute in any builds of the job.

A pipeline's jobs are listed under \reference{schema.pipeline.jobs} with the
following schema:

\schema{job}{
  \required-attribute{name}{identifier}{
    The name of the job. This should be short; it will show up in URLs. If you
    want to rename a job, use \reference{schema.job.old_name}.
  }

  \required-attribute{plan}{[step]}{
    The sequence of \reference{steps}{steps} to execute.
  }

  \optional-attribute{old_name}{identifier}{
    The old name of the job. If configured, the history of old job will be
    inherited to the new one. Once the pipeline is set, this field can be
    removed as the builds have been transfered.

    \example-toggle{Renaming a job}{
      This can be used to rename a job without losing its history, like so:

      \codeblock{yaml}{{
      jobs:
      - name: new-name
        old_name: current-name
        plan: [{get: 10m}]
      }}

      After the pipeline is set, because the builds have been inherited, the job can
      have the field removed:

      \codeblock{yaml}{{
      jobs:
      - name: new-name
        plan: [{get: 10m}]
      }}
    }
  }

  \optional-attribute{serial}{boolean}{
    \italic{Default \code{false}.} If set to \code{true}, builds will queue up
    and execute one-by-one, rather than executing in parallel.
  }

  \optional-attribute{serial_groups}{[identifier]}{
    \italic{Default \code{[]}.} When set to an array of arbitrary tag-like
    strings, builds of this job and other jobs referencing the same tags will
    be serialized.

    \example-toggle{Limiting parallelism}{
      This can be used to ensure that certain jobs do not run at the same time,
      like so:

      \codeblock{yaml}{{
      jobs:
      - name: job-a
        serial_groups: [some-tag]
      - name: job-b
        serial_groups: [some-tag, some-other-tag]
      - name: job-c
        serial_groups: [some-other-tag]
      }}

      In this example, \code{job-a} and \code{job-c} can run concurrently, but
      neither job can run builds at the same time as \code{job-b}.

      The builds are executed in their order of creation, across all jobs with
      common tags.
    }
  }

  \optional-attribute{max_in_flight}{number}{
    If set, specifies a maximum number of builds to run at a time. If
    \code{serial} or \code{serial_groups} are set, they take precedence and
    force this value to be \code{1}.
  }

  \optional-attribute{build_log_retention}{build_log_retention_policy}{
    Configures the retention policy for build logs. This is useful if you have
    a job that runs often but after some amount of time the logs aren't worth
    keeping around.

    Builds which are not retained by the configured policy will have their logs
    reaped. If this configuration is omitted, logs are kept forever (unless
    \reference{build-log-retention} is configured globally).

    \example-toggle{A complicated example}{
      The following example will keep logs for any builds that have completed in
      the last 2 days, while also keeping the last 1000 builds and at least 1
      succeeded build.

      \codeblock{yaml}{{{
      jobs:
      - name: smoke-tests
        build_log_retention:
          days: 2
          builds: 1000
          minimum_succeeded_builds: 1
        plan:
        - get: 10m
        - task: smoke-tests
          # ...
      }}}

      If more than 1000 builds finish in the past 2 days, \italic{all} of them
      will be retained thanks to the
      \reference{schema.build_log_retention_policy.days}{\code{days}}
      configuration. Similarly, if there are 1000 builds spanning more than 2
      days, they will also be kept thanks to the
      \reference{schema.build_log_retention_policy.builds}{\code{builds}}
      configuration. And if they all happened to have failed, the
      \reference{schema.build_log_retention_policy.minimum_succeeded_builds}{\code{minimum_succeeded_builds}}
      will keep around at least one successful build. All policies operate
      independently.
    }

    \schema{build_log_retention_policy}{
      \optional-attribute{days}{number}{
        Keep logs for builds which have finished within the specified number of
        days.
      }

      \optional-attribute{builds}{number}{
        Keep logs for the last specified number of builds.
      }

      \optional-attribute{minimum_succeeded_builds}{number}{
        Keep a minimum number of successful build logs that would normally be
        reaped.

        Requires
        \reference{schema.build_log_retention_policy.builds}{\code{builds}} to
        be set to an integer higher than 0 in order to work. For example, if
        \reference{schema.build_log_retention_policy.builds}{\code{builds}} is
        set to 5, and this attribute to 1, say a job has the following build
        history: 7(f), 6(f), 5(f), 4(f), 3(f), 2(f), 1(s), where f means
        failed and s means succeeded, then builds 2 and 3 will be reaped,
        because it retains 5 build logs, and at least 1 succeeded build log.
        Default is 0.
      }
    }
  }

  \optional-attribute{build_logs_to_retain}{number}{
    \italic{Deprecated.} Equivalent to setting
    \reference{schema.build_log_retention_policy.builds}{\code{job.build_log_retention.builds}}.
  }

  \optional-attribute{public}{boolean}{
    \italic{Default \code{false}.} If set to \code{true}, the build log of this
    job will be viewable by unauthenticated users. Unauthenticated users will
    always be able to see the inputs, outputs, and build status history of a
    job. This is useful if you would like to expose your pipeline publicly
    without showing sensitive information in the build log.

    Note: when this is set to \code{true}, any \reference{get-step} and
    \reference{put-step}s will show the metadata for their resource version,
    regardless of whether the resource itself has set \reference{schema.resource.public}
    to \code{true}.
  }

  \optional-attribute{disable_manual_trigger}{boolean}{
    \italic{Default \code{false}.} If set to \code{true}, manual triggering of
    the job (via the web UI or \reference{fly-trigger-job}) will be disabled.
  }

  \optional-attribute{interruptible}{boolean}{
    \italic{Default \code{false}.} Normally, when a worker is shutting down it
    will wait for builds with containers running on that worker to finish
    before exiting. If this value is set to \code{true}, the worker will not
    wait on the builds of this job. You may want this if e.g. you have a
    self-deploying Concourse or long-running-but-low-importance jobs.
  }

  \optional-attribute{on_success}{step}{
    Step to execute when the job succeeds. Equivalent to the
    \reference{schema.on_success} hook.
  }

  \optional-attribute{on_failure}{step}{
    Step to execute when the job fails. Equivalent to the
    \reference{schema.on_failure} hook.
  }

  \optional-attribute{on_error}{step}{
    Step to execute when the job errors. Equivalent to the
    \reference{schema.on_error} hook.
  }

  \optional-attribute{on_abort}{step}{
    Step to execute when the job aborts. Equivalent to the
    \reference{schema.on_abort} hook.
  }

  \optional-attribute{ensure}{step}{
    Step to execute regardless of whether the job succeeds, fails, errors, or
    aborts. Equivalent to the \reference{schema.ensure} hook.
  }
}

\table-of-contents

\include-section{jobs/managing.lit}
